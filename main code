
import torch
from torch.utils.data import Dataset, DataLoader
from torchvision.transforms import ToTensor, Normalize, Compose, Resize, RandomHorizontalFlip, RandomVerticalFlip, ColorJitter, RandomRotation
from torchvision.models import vgg19
from PIL import Image
import os
import matplotlib.pyplot as plt
import torch.nn as nn
import torch.optim as optim
import torchvision.transforms.functional as TF


# Define the generator and discriminator networks
class Generator(nn.Module):
    def __init__(self, latent_size, image_size):
        super(Generator, self).__init__()
        self.latent_size = latent_size
        self.image_size = image_size

        self.model = nn.Sequential(
            nn.Linear(latent_size, 512),
            nn.ReLU(),
            nn.Linear(512, 1024),
            nn.ReLU(),
            nn.Linear(1024, 2048),
            nn.ReLU(),
            nn.Linear(2048, image_size),
            nn.Tanh()
        )

    def forward(self, x):
        return self.model(x)


 class Discriminator(nn.Module):
    def __init__(self, image_size):
        super(Discriminator, self).__init__()
        self.image_size = image_size

        self.model = nn.Sequential(
            nn.Linear(image_size, 1024),
            nn.LeakyReLU(0.2),
            nn.Linear(1024, 512),
            nn.LeakyReLU(0.2),
            nn.Linear(512, 1),
            nn.Sigmoid()
        )

    def forward(self, x):
        x = x.view(-1, self.image_size)  # Flatten the input
        return self.model(x)



# Define dataset class with data augmentation
class CustomDataset(Dataset):
    def __init__(self, root_dir, transform=None):
        self.root_dir = root_dir
        self.transform = transform
        self.images = [img for img in os.listdir(root_dir) if img.endswith(".jpg")]

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        img_path = os.path.join(self.root_dir, self.images[idx])
        _image = Image.open(img_path).convert('L')  # convert image to grayscale

        # Apply data augmentation
        if self.transform:
            _image = self.transform(_image)

        # Normalize the image to [-1, 1]
        _image = Normalize(mean=(0.5,), std=(0.5,))(_image)

        # Extract label from image filename
        label = self.images[idx].split('_')[0]  # assuming the format is 'label_anything.jpg'

        return _image, label



 # Initialize dataset with data augmentation
transform = Compose([
    Resize((128, 128)),
    RandomHorizontalFlip(),
    RandomVerticalFlip(),
    ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
    RandomRotation(10),
    ToTensor()
])
dataset = CustomDataset(root_dir=dir, transform=transform)



# Plot original images
plt.figure(figsize=(10, 10))
for i in range(25):
    sample_image, _ = dataset[i]
    plt.subplot(5, 5, i+1)
    plt.imshow(sample_image[0], cmap='gray')
    plt.axis('off')
plt.show()




# Initialize dataloader
data_loader = DataLoader(dataset, batch_size=128, shuffle=True)

# Device configuration
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# Initialize generator and discriminator
latent_size = 100
image_size = 128 * 128
G = Generator(latent_size, image_size).to(device)
D = Discriminator(image_size).to(device)



# Load pre-trained VGG-19 model for perceptual loss
vgg = vgg19(pretrained=True).features[:35].to(device).eval()

# Modify VGG-19 input size
class VGG(nn.Module):
    def __init__(self):
        super(VGG, self).__init__()
        self.features = vgg

    def forward(self, x):
        x = x.repeat(1, 3, 1, 1)  # Convert grayscale to RGB by repeating the single channel 3 times
        return self.features(x)

vgg_model = VGG().to(device)



# Loss functions
criterion = nn.BCELoss()
mse_loss = nn.MSELoss()

# Optimizers
g_optimizer = optim.Adam(G.parameters(), lr=0.0002, betas=(0.5, 0.999))
d_optimizer = optim.Adam(D.parameters(), lr=0.0002, betas=(0.5, 0.999))





# Training loop
num_epochs =8000
for epoch in range(num_epochs):
    for i, (images, _) in enumerate(data_loader):
        real_images = images.view(-1, image_size).to(device)

        # Train discriminator
        d_optimizer.zero_grad()
        real_labels = torch.ones(images.size(0), 1).to(device)
        fake_labels = torch.zeros(images.size(0), 1).to(device)

        # Train discriminator on real images
        real_outputs = D(real_images)
        d_loss_real = criterion(real_outputs, real_labels)
        real_score = real_outputs.mean().item()

        # Train discriminator on fake images
        z = torch.randn(images.size(0), latent_size).to(device)
        fake_images = G(z)
        fake_outputs = D(fake_images.detach())
        d_loss_fake = criterion(fake_outputs, fake_labels)
        fake_score = fake_outputs.mean().item()

        # Backpropagation
        d_loss = d_loss_real + d_loss_fake
        d_loss.backward()
        d_optimizer.step()

        # Train generator
        g_optimizer.zero_grad()
        z = torch.randn(images.size(0), latent_size).to(device)
        fake_images = G(z)
        outputs = D(fake_images)
        g_loss = criterion(outputs, real_labels)

        # Load pre-trained VGG-19 model for perceptual loss
        vgg_model = VGG().to(device).eval()

        # Perceptual loss
        vgg_real_features = vgg_model(real_images)
        vgg_fake_features = vgg_model(fake_images)
        perceptual_loss = mse_loss(vgg_real_features, vgg_fake_features)


        # Total loss
        total_loss = g_loss + 0.1 * perceptual_loss
        total_loss.backward()
        g_optimizer.step()

        if (i+1) % 100 == 0:
            print('Epoch [{}/{}], Step [{}/{}], d_loss: {:.4f}, g_loss: {:.4f}, perceptual_loss: {:.4f}, D(x): {:.2f}, D(G(z)): {:.2f}'
                  .format(epoch+1, num_epochs, i+1, len(data_loader), d_loss.item(), g_loss.item(),
                          perceptual_loss.item(), real_score, fake_score))
    print("Epoch",epoch,"Done!")
# Save the trained model
torch.save(G.state_dict(), 'generator.ckpt')
torch.save(D.state_dict(), 'discriminator.ckpt')



# Generate and plot synthetic images
with torch.no_grad():
    num_samples = 10
    z = torch.randn(num_samples, latent_size).to(device)
    fake_images = G(z).view(-1, 1, 128, 128).cpu()

    plt.figure(figsize=(10, 1))
    for k in range(num_samples):
        plt.subplot(1, num_samples, k+1)
        plt.imshow(fake_images[k][0], cmap='gray', vmin=-1, vmax=1)
        plt.axis('off')
    plt.show()




import os
import torch
from torchvision.utils import save_image
import matplotlib.pyplot as plt

# Define the generator architecture
class Generator(nn.Module):
    def __init__(self, latent_size, image_size):
        super(Generator, self).__init__()
        self.latent_size = latent_size
        self.image_size = image_size

        self.model = nn.Sequential(
            nn.Linear(latent_size, 512),
            nn.ReLU(),
            nn.Linear(512, 1024),
            nn.ReLU(),
            nn.Linear(1024, 2048),
            nn.ReLU(),
            nn.Linear(2048, image_size),
            nn.Tanh()
        )

    def forward(self, x):
        return self.model(x)

# Load the generator model
generator = Generator(latent_size, image_size)
generator.load_state_dict(torch.load(r'C:\Users\mrunm\OneDrive\Desktop\Major_Project_Code\generator_(1).ckpt'))
generator.eval()

# Create directory to save generated images
os.makedirs('generated_images', exist_ok=True)

# Generate and save images
num_images = 10  # Number of images to generate
latent_size = 100  # Size of the latent vector

# Generate random latent vectors
latent_vectors = torch.randn(num_images, latent_size)

# Generate images from latent vectors
with torch.no_grad():
    generated_images = generator(latent_vectors)

# Reshape generated images to 2D and convert to the range [0, 1]
generated_images = generated_images.view(num_images, 1, 128, 128)  # Assuming image_size is 128x128
generated_images = (generated_images + 1) / 2  # Scale to [0, 1] range

# Save generated images
for i in range(num_images):
    save_image(generated_images[i], f'generated_images/generated_image_{i}.png')

# Show generated images one by one
for i in range(num_images):
    image_path = f'generated_images/generated_image_{i}.png'
    image = plt.imread(image_path)
    plt.imshow(image, cmap='gray')
    plt.title(f'Generated Image {i+1}')
    plt.axis('off')
    plt.show()



